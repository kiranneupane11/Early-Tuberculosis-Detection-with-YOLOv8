{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6370358,"sourceType":"datasetVersion","datasetId":3057430},{"sourceId":7737931,"sourceType":"datasetVersion","datasetId":4522446}],"dockerImageVersionId":30648,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Initializing Directory","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T04:00:24.603989Z","start_time":"2024-02-24T04:00:24.593062Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T18:12:39.879076Z","iopub.execute_input":"2024-03-04T18:12:39.879750Z","iopub.status.idle":"2024-03-04T18:12:39.885960Z","shell.execute_reply.started":"2024-03-04T18:12:39.879718Z","shell.execute_reply":"2024-03-04T18:12:39.885172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ROOT PATH\nROOT_PATH = '.'\nDATA_PATH = f'{ROOT_PATH}/data'\nPROCESSED_PATH = f'{DATA_PATH}/processed'\n\nos.makedirs(PROCESSED_PATH, exist_ok=True)","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T04:00:24.930934Z","start_time":"2024-02-24T04:00:24.920906Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T18:12:40.970959Z","iopub.execute_input":"2024-03-04T18:12:40.971868Z","iopub.status.idle":"2024-03-04T18:12:40.976434Z","shell.execute_reply.started":"2024-03-04T18:12:40.971833Z","shell.execute_reply":"2024-03-04T18:12:40.975493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup for Kaggle","metadata":{}},{"cell_type":"code","source":"# Run this if you are in Kaggle and has linked via inline kaggle dataset:\n\n# if os.environ.get('MPLBACKEND') == 'agg':\n#     source_path = '/kaggle/input/tuberculosis-tb-chest-x-ray-cleaned-database/TB Chest Radiography Database/TB Chest Radiography Database/Cleaned Data'\n#     destination_path = f'{DATA_PATH}/clean'\n#     external_dataset_path = '/kaggle/input/tuberculosis-chest-xrays-shenzhen/images/images'\n#     destination_external_dataset = f'{DATA_PATH}/external_test'\n#     shutil.copytree(source_path, destination_path)\n#     print(f\"File copied from {source_path} to {destination_path}\")\n\n\nexternal_dataset_path = '/kaggle/input/tuberculosis-chest-xrays-shenzhen/images/images'\ndestination_external_dataset = f'{DATA_PATH}/external_test'\nshutil.copytree(external_dataset_path, destination_external_dataset)","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T04:00:35.842341Z","start_time":"2024-02-24T04:00:35.836304Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T19:17:19.922483Z","iopub.execute_input":"2024-03-04T19:17:19.923643Z","iopub.status.idle":"2024-03-04T19:17:24.347790Z","shell.execute_reply.started":"2024-03-04T19:17:19.923601Z","shell.execute_reply":"2024-03-04T19:17:24.346605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import uuid\nimport pandas as pd\nfrom PIL import Image","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T04:00:36.335532Z","start_time":"2024-02-24T04:00:36.333262Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T19:16:27.221681Z","iopub.status.idle":"2024-03-04T19:16:27.221989Z","shell.execute_reply.started":"2024-03-04T19:16:27.221835Z","shell.execute_reply":"2024-03-04T19:16:27.221848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_image_dataframe(directory, class_name, class_id):\n    if class_name is None or class_id is None:\n        return Exception('Please insert class name and class id')\n\n    data = []  # List to store dictionary of image properties\n\n    # Iterate through all files in the directory\n    for root, dirs, files in os.walk(directory):\n        for filename in files:\n            # Construct the full file path\n            file_path = os.path.join(root, filename)\n            try:\n                # Open the image to get its size\n                with Image.open(file_path) as img:\n                    width, height = img.size\n                    size = f\"{width}x{height}\"\n                format = os.path.splitext(filename)[1].lstrip('.').upper()\n                data.append({\n                    'FILE NAME': filename.split('.')[0],\n                    'SIZE': size,\n                    'CLASS_ID': class_id,\n                    'CLASS_NAME': class_name,\n                    'FORMAT': format\n                })\n            except IOError:\n                # Skip files that are not images\n                continue\n\n    # Create a DataFrame from the list of image properties\n    df = pd.DataFrame(data, columns=['FILE NAME', 'SIZE', 'CLASS_ID', 'CLASS_NAME', 'FORMAT'])\n    return df\n\n\ndef prepare_clean_dataset():\n    # Specify the directory containing the images\n    normal_directory = f'{DATA_PATH}/clean/Normal'\n    tb_directory = f'{DATA_PATH}/clean/Tuberculosis'\n\n    # Create the DataFrame\n    normal_df_from_files = create_image_dataframe(normal_directory, class_name='Normal', class_id=0)\n    tb_df_from_files = create_image_dataframe(tb_directory, class_name='Tuberculosis', class_id=1)\n\n    tb_csv_path = f'{DATA_PATH}/clean/tuberculosis.csv'\n    normal_csv_path = f'{DATA_PATH}/clean/normal.csv'\n    normal_df_from_files.to_csv(normal_csv_path)\n    normal_df_from_files.to_csv(tb_csv_path)\n\n    shutil.copy(normal_csv_path, f'{PROCESSED_PATH}/normal.csv')\n    shutil.copy(tb_csv_path, f'{PROCESSED_PATH}/tuberculosis.csv')\n\n    print(\n        f'\\n\\n✅ Cleaned Dataset CSV is now available in the following path :\\nNormal\\t\\t:\\t\\t{PROCESSED_PATH}/normal.csv\\nTuberculosis \\t:\\t\\t{PROCESSED_PATH}/tuberculosis.csv\\n\\n')\n    return tb_df_from_files, normal_df_from_files","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:58:36.436950Z","start_time":"2024-02-24T03:58:36.431280Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:07:47.396102Z","iopub.execute_input":"2024-03-04T12:07:47.396808Z","iopub.status.idle":"2024-03-04T12:07:47.408081Z","shell.execute_reply.started":"2024-03-04T12:07:47.396775Z","shell.execute_reply":"2024-03-04T12:07:47.406816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tb_df, normal_df = prepare_clean_dataset();","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T02:57:48.477314Z","start_time":"2024-02-24T02:57:47.438589Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:07:48.547299Z","iopub.execute_input":"2024-03-04T12:07:48.547958Z","iopub.status.idle":"2024-03-04T12:07:49.103435Z","shell.execute_reply.started":"2024-03-04T12:07:48.547928Z","shell.execute_reply":"2024-03-04T12:07:49.102422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tb_df.head()","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T02:57:49.376005Z","start_time":"2024-02-24T02:57:49.352419Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T18:12:44.388756Z","iopub.execute_input":"2024-03-04T18:12:44.389484Z","iopub.status.idle":"2024-03-04T18:12:44.400317Z","shell.execute_reply.started":"2024-03-04T18:12:44.389453Z","shell.execute_reply":"2024-03-04T18:12:44.399246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normal_df.head()","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T02:57:53.589727Z","start_time":"2024-02-24T02:57:53.567621Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:07:50.663799Z","iopub.execute_input":"2024-03-04T12:07:50.664435Z","iopub.status.idle":"2024-03-04T12:07:50.675341Z","shell.execute_reply.started":"2024-03-04T12:07:50.664401Z","shell.execute_reply":"2024-03-04T12:07:50.674429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_csv(file_path, output_path=f'{PROCESSED_PATH}', file_name=f'{uuid.uuid4()}'):\n    os.makedirs(output_path, exist_ok=True)\n    excel_file_path = file_path\n    out = f'{output_path}/{file_name}.csv'\n    df = pd.read_excel(excel_file_path)\n    df.to_csv(out, index=False)\n    print(f'File converted and saved as {out}')\n\n\ndef read_csv(file_path):\n    return pd.read_csv(file_path)","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T02:57:55.922862Z","start_time":"2024-02-24T02:57:55.911720Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:07:51.459947Z","iopub.execute_input":"2024-03-04T12:07:51.460761Z","iopub.status.idle":"2024-03-04T12:07:51.466249Z","shell.execute_reply.started":"2024-03-04T12:07:51.460729Z","shell.execute_reply":"2024-03-04T12:07:51.465304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert_to_csv(f'{DATA_PATH}/org/Normal.metadata.xlsx', file_name='normal')\n# convert_to_csv(f'{DATA_PATH}/org/Tuberculosis.metadata.xlsx', file_name='tuberculosis')","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T02:57:56.334971Z","start_time":"2024-02-24T02:57:56.326164Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:07:52.465441Z","iopub.execute_input":"2024-03-04T12:07:52.465781Z","iopub.status.idle":"2024-03-04T12:07:52.469803Z","shell.execute_reply.started":"2024-03-04T12:07:52.465756Z","shell.execute_reply":"2024-03-04T12:07:52.468848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NORMAL_CSV_PATH = f'{PROCESSED_PATH}/normal.csv'\n# TUBERCULOSIS_CSV_PATH = f'{PROCESSED_PATH}/tuberculosis.csv'\n# \n# # Load Normal Data CSV\n# normal_df = read_csv(file_path=NORMAL_CSV_PATH)\n# normal_df = normal_df.drop(columns=['URL'])\n# normal_df['CLASS_ID'] = 0\n# normal_df['CLASS_NAME'] = 'NORMAL'\n# \n# # Load Tuberculosis Data CSV\n# tb_df = read_csv(file_path=TUBERCULOSIS_CSV_PATH)\n# tb_df = tb_df.drop(columns=['URL'])\n# tb_df['CLASS_ID'] = 1\n# tb_df['CLASS_NAME'] = 'TUBERCULOSIS'","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T02:57:57.096259Z","start_time":"2024-02-24T02:57:57.046700Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:07:52.710646Z","iopub.execute_input":"2024-03-04T12:07:52.711001Z","iopub.status.idle":"2024-03-04T12:07:52.715334Z","shell.execute_reply.started":"2024-03-04T12:07:52.710973Z","shell.execute_reply":"2024-03-04T12:07:52.714406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tb_images_path_list = tb_df['FILE NAME'].apply(lambda x: f'{DATA_PATH}/clean/Tuberculosis/{x}.png')\ntb_images_path_list[0:4]","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T02:57:58.473645Z","start_time":"2024-02-24T02:57:58.450150Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:07:54.070068Z","iopub.execute_input":"2024-03-04T12:07:54.070718Z","iopub.status.idle":"2024-03-04T12:07:54.082105Z","shell.execute_reply.started":"2024-03-04T12:07:54.070686Z","shell.execute_reply":"2024-03-04T12:07:54.081111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentation","metadata":{}},{"cell_type":"code","source":"augmentation_required = len(normal_df) - len(tb_df);\nprint(\n    f\"\\n\\nData Info :\\nTuberculosis\\t:\\t\\t{len(tb_df)} [REQUIRED AUGMENTATION : {augmentation_required} ]\\nNormal\\t\\t\\t:\\t\\t{len(normal_df)}\")","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T02:59:09.907318Z","start_time":"2024-02-24T02:59:09.887428Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:07:56.742367Z","iopub.execute_input":"2024-03-04T12:07:56.742696Z","iopub.status.idle":"2024-03-04T12:07:56.747831Z","shell.execute_reply.started":"2024-03-04T12:07:56.742671Z","shell.execute_reply":"2024-03-04T12:07:56.746824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as A\nfrom albumentations.core.composition import Compose\nimport random","metadata":{"execution":{"iopub.status.busy":"2024-03-04T12:07:58.652416Z","iopub.execute_input":"2024-03-04T12:07:58.652777Z","iopub.status.idle":"2024-03-04T12:07:58.657501Z","shell.execute_reply.started":"2024-03-04T12:07:58.652747Z","shell.execute_reply":"2024-03-04T12:07:58.656301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define your augmentation pipeline\nAT = Compose([\n    A.Rotate(limit=(-5, 5), p=1),  # Rotation between -5 and 5 degrees\n    A.RandomScale(scale_limit=(0.01, 0.02), p=1)  # Small scaling\n])\n","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T02:59:12.667046Z","start_time":"2024-02-24T02:59:12.654418Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:07:58.826396Z","iopub.execute_input":"2024-03-04T12:07:58.826760Z","iopub.status.idle":"2024-03-04T12:07:58.832353Z","shell.execute_reply.started":"2024-03-04T12:07:58.826731Z","shell.execute_reply":"2024-03-04T12:07:58.831252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to perform augmentation and save the augmented images\nimport numpy as np\nfrom tqdm import  tqdm\n\n\ndef augment_image(save_dir, num_augmented_images=5):\n    properties = []\n    for i in tqdm(range(num_augmented_images), desc=\"Augmenting Images\"):\n        image_path = random.choice(tb_images_path_list)\n        image = Image.open(image_path)\n        image_np = np.array(image)\n        # Perform augmentation\n        augmented = AT(image=image_np)\n        augmented_image = Image.fromarray(augmented['image'])\n\n        extension = 'png'\n        # Save the augmented image\n        filename = f\"augmented_{i}_{os.path.basename(image_path).split('.')[0]}\"\n        augmented_image_path = os.path.join(save_dir, f'{filename}.{extension}')\n        augmented_image.save(augmented_image_path)\n\n        # Get image size\n        width, height = augmented_image.size\n\n        # Append properties to the list\n        properties.append({\n            'FILE NAME': filename,\n            'FORMAT': extension.upper(),  # Assuming you're saving as PNG\n            'SIZE': f\"{width}x{height}\",\n            'CLASS_ID': \"1\",\n            'CLASS_NAME': \"TUBERCULOSIS\",\n        })\n\n    return properties\n\n\ndef augment_and_save():\n    save_dir = f'{DATA_PATH}/clean/Tuberculosis'\n    # Ensure the save directory exists\n    os.makedirs(save_dir, exist_ok=True)\n\n    # DataFrame to store properties of all augmented images\n    df_properties = pd.DataFrame(columns=['FILE NAME', 'FORMAT', 'SIZE', 'CLASS_ID', 'CLASS_NAME'])\n\n    image_properties = augment_image(save_dir, num_augmented_images=augmentation_required)\n    df_properties = pd.concat([df_properties, pd.DataFrame(image_properties)], ignore_index=True)\n\n    # Export the DataFrame to CSV\n    csv_file_path = f'{PROCESSED_PATH}/tb_augmented.csv'  # Specify your desired CSV file path\n    df_properties.to_csv(csv_file_path, index=False)\n\n    print(f\"✅ Augmentation completed and properties saved to CSV. \\n📁Output directory : {save_dir}\")\n","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T02:59:39.672899Z","start_time":"2024-02-24T02:59:39.658733Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:07:59.746596Z","iopub.execute_input":"2024-03-04T12:07:59.747312Z","iopub.status.idle":"2024-03-04T12:07:59.757706Z","shell.execute_reply.started":"2024-03-04T12:07:59.747279Z","shell.execute_reply":"2024-03-04T12:07:59.756703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augment_and_save()","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:00:31.161365Z","start_time":"2024-02-24T02:59:41.555366Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:08:01.203144Z","iopub.execute_input":"2024-03-04T12:08:01.203510Z","iopub.status.idle":"2024-03-04T12:08:01.216150Z","shell.execute_reply.started":"2024-03-04T12:08:01.203482Z","shell.execute_reply":"2024-03-04T12:08:01.215260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augmented_tb_df = read_csv(f'{PROCESSED_PATH}/tb_augmented.csv')\naugmented_tb_df.head()","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:05:02.142601Z","start_time":"2024-02-24T03:05:02.076441Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:08:02.980758Z","iopub.execute_input":"2024-03-04T12:08:02.981126Z","iopub.status.idle":"2024-03-04T12:08:02.994277Z","shell.execute_reply.started":"2024-03-04T12:08:02.981094Z","shell.execute_reply":"2024-03-04T12:08:02.993255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tb_final_df = pd.concat([tb_df, augmented_tb_df])","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:05:04.558573Z","start_time":"2024-02-24T03:05:04.541596Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:08:04.189803Z","iopub.execute_input":"2024-03-04T12:08:04.190541Z","iopub.status.idle":"2024-03-04T12:08:04.200886Z","shell.execute_reply.started":"2024-03-04T12:08:04.190505Z","shell.execute_reply":"2024-03-04T12:08:04.199969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\n    f\"[ ✅ Data set ready for processing ]\\nNormal Data Count \\t\\t\\t:\\t\\t\\t{len(normal_df)}\\nTuberculosis Data Count\\t\\t:\\t\\t\\t{len(tb_final_df)}\")","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:05:08.195683Z","start_time":"2024-02-24T03:05:08.185232Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:08:06.279737Z","iopub.execute_input":"2024-03-04T12:08:06.280597Z","iopub.status.idle":"2024-03-04T12:08:06.285394Z","shell.execute_reply.started":"2024-03-04T12:08:06.280559Z","shell.execute_reply":"2024-03-04T12:08:06.284476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:05:10.877123Z","start_time":"2024-02-24T03:05:10.861907Z"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_df = pd.concat([tb_df, normal_df]).sample(frac=1).reset_index(drop=True)\nmerged_df.to_csv(f'{PROCESSED_PATH}/merged_dataset.csv')\nmerged_df.head()","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:05:11.160633Z","start_time":"2024-02-24T03:05:11.128149Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:08:07.837922Z","iopub.execute_input":"2024-03-04T12:08:07.838718Z","iopub.status.idle":"2024-03-04T12:08:07.881047Z","shell.execute_reply.started":"2024-03-04T12:08:07.838685Z","shell.execute_reply":"2024-03-04T12:08:07.880094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define a function that constructs the path based on the class\ndef construct_path(row):\n    if row['CLASS_ID'] == 0:\n        return f'{DATA_PATH}/clean/Normal/{row[\"FILE NAME\"]}.png'\n    elif row['CLASS_ID'] == 1:\n        return f'{DATA_PATH}/clean/Tuberculosis/{row[\"FILE NAME\"]}.png'\n    else:\n        return None  # Or some default path\n\n\n# Apply the function to each row of the DataFrame to generate the paths\nmerged_df['IMAGE PATH'] = merged_df.apply(construct_path, axis=1)\nmerged_images_path_list = merged_df['IMAGE PATH'].apply(lambda x: x)\nmerged_images_path_list[0:5]","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:07:00.198596Z","start_time":"2024-02-24T03:07:00.136805Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:08:12.621082Z","iopub.execute_input":"2024-03-04T12:08:12.621728Z","iopub.status.idle":"2024-03-04T12:08:12.752454Z","shell.execute_reply.started":"2024-03-04T12:08:12.621692Z","shell.execute_reply":"2024-03-04T12:08:12.751544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preparation for Tuberculosis Classification","metadata":{}},{"cell_type":"markdown","source":"## Train, test and validation split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:07:00.847253Z","start_time":"2024-02-24T03:07:00.832404Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:08:15.102885Z","iopub.execute_input":"2024-03-04T12:08:15.103689Z","iopub.status.idle":"2024-03-04T12:08:15.107784Z","shell.execute_reply.started":"2024-03-04T12:08:15.103656Z","shell.execute_reply":"2024-03-04T12:08:15.106771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_val_df, test_df = train_test_split(merged_df, test_size=0.2, random_state=42)\ntrain_df, val_df = train_test_split(train_val_df, test_size=0.125, random_state=42)  # 0.125 x 0.8 = 0.1","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:07:01.066505Z","start_time":"2024-02-24T03:07:01.036535Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:08:15.344767Z","iopub.execute_input":"2024-03-04T12:08:15.345151Z","iopub.status.idle":"2024-03-04T12:08:15.358963Z","shell.execute_reply.started":"2024-03-04T12:08:15.345120Z","shell.execute_reply":"2024-03-04T12:08:15.357989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing Image Dataset","metadata":{}},{"cell_type":"code","source":"import re\n\ndef to_sentence_case(text):\n    # Split the text into sentences using a regular expression\n    sentences = re.split('(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n    \n    # Capitalize the first letter of each sentence and join them back\n    sentence_case_text = '. '.join(sentence.capitalize() for sentence in sentences)\n    \n    return sentence_case_text","metadata":{"execution":{"iopub.status.busy":"2024-03-04T12:08:20.542984Z","iopub.execute_input":"2024-03-04T12:08:20.543375Z","iopub.status.idle":"2024-03-04T12:08:20.548802Z","shell.execute_reply.started":"2024-03-04T12:08:20.543344Z","shell.execute_reply":"2024-03-04T12:08:20.547883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\n\nclass ImageDataset(Dataset):\n    def __init__(self, dataframe, data_path, transform=None):\n        self.dataframe = dataframe\n        self.data_path = data_path\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        img_name = row['FILE NAME']\n        class_name = row['CLASS_NAME']\n        format = row['FORMAT'].lower()\n        img_path = os.path.join(self.data_path, 'clean', to_sentence_case(class_name), f'{img_name}.{format}')\n        image = Image.open(img_path)\n        label = row['CLASS_ID']\n\n        if self.transform:\n            image = self.transform(image)\n\n        sample = {'image': image, 'label': label, 'img_path': img_path, 'attributes': row.to_dict()}\n        return sample\n","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:09:02.843098Z","start_time":"2024-02-24T03:09:02.831127Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:08:20.718265Z","iopub.execute_input":"2024-03-04T12:08:20.718629Z","iopub.status.idle":"2024-03-04T12:08:20.727226Z","shell.execute_reply.started":"2024-03-04T12:08:20.718599Z","shell.execute_reply":"2024-03-04T12:08:20.726086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_samples(dataset, name, num_samples=5):\n    print(f\"Samples from {name} dataset:\")\n    plt.figure(figsize=(10, num_samples * 2))  # Set the figure size\n\n    for i in range(num_samples):\n        sample = dataset[i]  # Using the modified __getitem__ method\n        image, img_path, attributes = sample['image'], sample['img_path'], sample['attributes']\n\n        # Adjust the image for plotting\n        if image.shape[0] == 1:  # Single-channel image\n            image = image.squeeze(0)  # Remove the channel dimension\n\n        # Plotting the image\n        ax = plt.subplot(num_samples, 1, i + 1)  # Change the layout to have 1 column\n        if image.ndim == 2:  # Grayscale image\n            ax.imshow(image, cmap='gray')  # Use cmap='gray' for grayscale images\n        else:\n            ax.imshow(image.permute(1, 2, 0))  # For RGB images, permute the dimensions\n        ax.axis('off')  # Hide the axes\n\n    plt.tight_layout()\n    plt.show()\n    print(\"\\n\")\n","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:09:03.646978Z","start_time":"2024-02-24T03:09:03.642688Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:08:20.851956Z","iopub.execute_input":"2024-03-04T12:08:20.852979Z","iopub.status.idle":"2024-03-04T12:08:20.860731Z","shell.execute_reply.started":"2024-03-04T12:08:20.852944Z","shell.execute_reply":"2024-03-04T12:08:20.859787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = (256, 256)","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:09:04.108734Z","start_time":"2024-02-24T03:09:04.102482Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:08:21.577558Z","iopub.execute_input":"2024-03-04T12:08:21.578422Z","iopub.status.idle":"2024-03-04T12:08:21.583829Z","shell.execute_reply.started":"2024-03-04T12:08:21.578385Z","shell.execute_reply":"2024-03-04T12:08:21.582728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:09:04.926866Z","start_time":"2024-02-24T03:09:04.918668Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:08:29.091095Z","iopub.execute_input":"2024-03-04T12:08:29.091463Z","iopub.status.idle":"2024-03-04T12:08:29.096078Z","shell.execute_reply.started":"2024-03-04T12:08:29.091433Z","shell.execute_reply":"2024-03-04T12:08:29.094999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pre transformation for normalization values","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\nimport os\n\n\n# Assuming you have a list of image paths\n\ndef calculate_mean_and_std():\n    # Define the initial transformations (without normalization)\n    pre_transforms = transforms.Compose([\n#         transforms.Grayscale(num_output_channels=3),\n        transforms.Resize(IMAGE_SIZE),\n        transforms.ToTensor(),\n    ])\n\n    # Initialize lists to store all pixel values for each channel\n    pixels = []\n\n    # Loop through all images\n    for image_path in tqdm(merged_images_path_list, desc=\"Calculating ... \"):\n        # Load image\n        img = Image.open(image_path)\n\n        # Apply initial transformations\n        img_tensor = pre_transforms(img)\n\n        # Flatten image tensor and add it to the list\n        pixels.append(img_tensor.view(-1))\n\n    # Concatenate all pixels to have a single tensor\n    all_pixels = torch.cat(pixels, dim=0)\n\n    # Calculate mean and std\n    mean = all_pixels.mean()\n    std = all_pixels.std()\n\n    return mean, std\n","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:09:07.088500Z","start_time":"2024-02-24T03:09:07.083197Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:08:29.873151Z","iopub.execute_input":"2024-03-04T12:08:29.873796Z","iopub.status.idle":"2024-03-04T12:08:29.880702Z","shell.execute_reply.started":"2024-03-04T12:08:29.873761Z","shell.execute_reply":"2024-03-04T12:08:29.879553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean, std = calculate_mean_and_std()","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:07:59.282390Z","start_time":"2024-02-24T03:07:05.616193Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:08:31.224647Z","iopub.execute_input":"2024-03-04T12:08:31.225334Z","iopub.status.idle":"2024-03-04T12:09:32.005446Z","shell.execute_reply.started":"2024-03-04T12:08:31.225300Z","shell.execute_reply":"2024-03-04T12:09:32.004636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\n\n\nclass CLAHETransform:\n    def __init__(self, clip_limit=2.0, tile_grid_size=(8, 8)):\n        self.clip_limit = clip_limit\n        self.tile_grid_size = tile_grid_size\n\n    def __call__(self, img):\n        # Convert PIL image to numpy array\n#         img_np = np.array(img)\n\n        # If the image is grayscale, convert it to a 3-channel image for CLAHE\n        if len(img_np.shape) == 2:\n            img_np = cv2.cvtColor(img_np, cv2.COLOR_GRAY2BGR)\n\n        # Initialize CLAHE\n        clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n\n        # Split the image into channels\n        channels = cv2.split(img_np)\n\n        # Apply CLAHE to each channel\n        clahe_channels = [clahe.apply(channel) for channel in channels]\n\n        # Merge the channels back\n        clahe_img = cv2.merge(clahe_channels)\n\n        # If the original image was grayscale, convert back to single channel\n        if len(img_np.shape) == 2:\n            clahe_img = cv2.cvtColor(clahe_img, cv2.COLOR_BGR2GRAY)\n\n        # Convert numpy array back to PIL Image\n        img = Image.fromarray(clahe_img)\n\n        return img","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:09:09.063998Z","start_time":"2024-02-24T03:09:09.055668Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:11:19.910892Z","iopub.execute_input":"2024-03-04T12:11:19.911284Z","iopub.status.idle":"2024-03-04T12:11:19.919959Z","shell.execute_reply.started":"2024-03-04T12:11:19.911253Z","shell.execute_reply":"2024-03-04T12:11:19.919054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"std.item()","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:58:02.407521Z","iopub.execute_input":"2024-03-04T16:58:02.407872Z","iopub.status.idle":"2024-03-04T16:58:02.414205Z","shell.execute_reply.started":"2024-03-04T16:58:02.407846Z","shell.execute_reply":"2024-03-04T16:58:02.413233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"T = transforms.Compose([\n#     CLAHETransform(),  # Uncomment or add your custom transforms as needed\n    transforms.Grayscale(num_output_channels=3),  # Convert images to 3-channel grayscale\n    transforms.Resize(IMAGE_SIZE),\n    transforms.ToTensor(),\n    # Normalize with mean and std for RGB images; adjust these values as per your dataset\n    transforms.Normalize(mean=[mean.item(), mean.item(), mean.item()], std=[std.item(), std.item(), std.item()]),\n])\n","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:16:11.574385Z","start_time":"2024-02-24T03:16:11.518043Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T18:40:39.124836Z","iopub.execute_input":"2024-03-04T18:40:39.125800Z","iopub.status.idle":"2024-03-04T18:40:39.132914Z","shell.execute_reply.started":"2024-03-04T18:40:39.125754Z","shell.execute_reply":"2024-03-04T18:40:39.131812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Initialize your custom dataset with transformations\ntrain_dataset = ImageDataset(train_df, DATA_PATH, transform=T)\nval_dataset = ImageDataset(val_df, DATA_PATH, transform=T)\ntest_dataset = ImageDataset(test_df, DATA_PATH, transform=T)\n\n# Create DataLoader for each set\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:16:11.998354Z","start_time":"2024-02-24T03:16:11.986003Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:13:24.920691Z","iopub.execute_input":"2024-03-04T12:13:24.921640Z","iopub.status.idle":"2024-03-04T12:13:24.928606Z","shell.execute_reply.started":"2024-03-04T12:13:24.921594Z","shell.execute_reply":"2024-03-04T12:13:24.927557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print a few samples from each dataset\nplot_samples(train_dataset, 'Train')\nplot_samples(val_dataset, 'Validation')\nplot_samples(test_dataset, 'Test')","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:16:12.961722Z","start_time":"2024-02-24T03:16:12.178146Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:13:25.863753Z","iopub.execute_input":"2024-03-04T12:13:25.864156Z","iopub.status.idle":"2024-03-04T12:13:26.695121Z","shell.execute_reply.started":"2024-03-04T12:13:25.864070Z","shell.execute_reply":"2024-03-04T12:13:26.694236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tuberculosis Classification\nThe model training involves the following steps:\n## 1. Preparing the model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\nIMAGE_INPUT_CHANNEL = 'RGB'\nKERNEL_SIZE = 3\nPOOL_KERNEL_SIZE = 2\n\nclass TuberculosisCNNReduced(nn.Module):\n    def __init__(self):\n        super(TuberculosisCNNReduced, self).__init__()\n        # Define a simplified CNN architecture with 10 layers in total\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=KERNEL_SIZE, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=POOL_KERNEL_SIZE, stride=2),  # Layer 1\n\n            nn.Conv2d(32, 64, kernel_size=KERNEL_SIZE, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=POOL_KERNEL_SIZE, stride=2),  # Layer 2\n\n            nn.Conv2d(64, 128, kernel_size=KERNEL_SIZE, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=POOL_KERNEL_SIZE, stride=2),  # Layer 3\n\n            nn.Conv2d(128, 256, kernel_size=KERNEL_SIZE, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=POOL_KERNEL_SIZE, stride=2),  # Layer 4\n        )\n\n        self.classifier = nn.Sequential(\n            nn.Linear(256 * (256 // (2 ** 4)) * (256 // (2 ** 4)), 1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),  # Layer 5\n            nn.Linear(1024, 256),\n            nn.ReLU(inplace=True),  # Layer 6\n            nn.Linear(256, 2),  # Layer 7\n        )\n\n    def forward(self, x):\n        x = self.features(x)  # Pass input through feature extractor\n        x = torch.flatten(x, 1)  # Flatten the features for the classifier\n        x = self.classifier(x)  # Pass through the classifier\n        return x\n\n# Initialize the reduced model\ntb_model = TuberculosisCNNReduced()\n","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:16:15.102467Z","start_time":"2024-02-24T03:16:14.166518Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:13:30.779923Z","iopub.execute_input":"2024-03-04T12:13:30.780764Z","iopub.status.idle":"2024-03-04T12:13:31.313077Z","shell.execute_reply.started":"2024-03-04T12:13:30.780733Z","shell.execute_reply":"2024-03-04T12:13:31.312258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tb_model","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:16:15.231922Z","start_time":"2024-02-24T03:16:15.222872Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:13:31.314633Z","iopub.execute_input":"2024-03-04T12:13:31.314928Z","iopub.status.idle":"2024-03-04T12:13:31.321389Z","shell.execute_reply.started":"2024-03-04T12:13:31.314902Z","shell.execute_reply":"2024-03-04T12:13:31.320456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plotting Functions","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import precision_recall_curve, confusion_matrix\nimport seaborn as sns\n\ndef plot_metrics(train_accuracies, val_accuracies, test_accuracies, true_labels, predicted_labels):\n    # Set up the matplotlib figure\n    plt.figure(figsize=(12, 10))\n\n    # Train vs Test Accuracy\n    plt.subplot(2, 2, 1)\n    plt.plot(train_accuracies, label='Train Accuracy')\n    plt.plot(test_accuracies, label='Test Accuracy')\n    plt.title('Train vs Test Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    # Train vs Validation Accuracy\n    plt.subplot(2, 2, 2)\n    plt.plot(train_accuracies, label='Train Accuracy')\n    plt.plot(val_accuracies, label='Validation Accuracy')\n    plt.title('Train vs Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    # Precision-Recall Curve\n    plt.subplot(2, 2, 3)\n    precision, recall, _ = precision_recall_curve(true_labels, predicted_labels)\n    plt.plot(recall, precision, marker='.')\n    plt.title('Precision-Recall Curve')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n\n    # Confusion Matrix\n    plt.subplot(2, 2, 4)\n    cm = confusion_matrix(true_labels, predicted_labels)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted Labels')\n    plt.ylabel('True Labels')\n\n    plt.tight_layout()\n    plt.show()\n    \n     # Define the directory path for saving the plots\n    save_dir = f'{DATA_PATH}/logs'\n    \n    # Create the directory if it does not exist\n    if not os.path.exists(save_dir):\n        os.makedirs(save_dir)\n    \n    # Save the figure\n    plt.savefig(f'{save_dir}/training_metrics.png')\n    plt.close()  # Close the figure to free memory\n\n","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:16:16.602229Z","start_time":"2024-02-24T03:16:16.581735Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T12:13:33.773726Z","iopub.execute_input":"2024-03-04T12:13:33.774400Z","iopub.status.idle":"2024-03-04T12:13:33.786301Z","shell.execute_reply.started":"2024-03-04T12:13:33.774366Z","shell.execute_reply":"2024-03-04T12:13:33.785213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Classification Model","metadata":{}},{"cell_type":"code","source":"LEARNING_RATE = 0.0001\nNUM_OF_EPOCHS = 50\n\nOPTIMIZER = 'SGD'  # Other options include 'SGD', 'RMSprop', 'AdamW', etc.","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:16:17.872082Z","start_time":"2024-02-24T03:16:17.842885Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T15:05:02.865932Z","iopub.execute_input":"2024-03-04T15:05:02.866857Z","iopub.status.idle":"2024-03-04T15:05:02.871493Z","shell.execute_reply.started":"2024-03-04T15:05:02.866807Z","shell.execute_reply":"2024-03-04T15:05:02.870519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport os\n\n# Assuming TuberculosisCNN and ImageDataset are defined elsewhere\n\nbest_val_accuracy = 0\n\ndef train_epoch(model, train_loader, criterion, optimizer, device):\n    model.train()\n    train_loss = 0.0\n    correct = 0\n    total = 0\n    for batch in tqdm(train_loader, desc=\"Training \\t\"):\n        images = batch['image'].to(device)\n        labels = batch['label'].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item() * images.size(0)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    train_accuracy = correct / total\n    return train_loss / len(train_loader.dataset), train_accuracy\n\ndef validate(model, val_loader, criterion, device):\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for batch in tqdm(val_loader, desc=\"Validating \\t\"):\n            images = batch['image'].to(device)\n            labels = batch['label'].to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item() * images.size(0)\n\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    val_accuracy = correct / total\n    return val_loss / len(val_loader.dataset), val_accuracy\n\ndef visualize_training_data(train_accuracies, val_accuracies, train_losses, val_losses, epoch=0, save_path='training_plots'):\n    plt.figure(figsize=(12, 6))\n\n    # Train vs Validation Accuracy\n    plt.subplot(1, 2, 1)\n    plt.plot(train_accuracies, label='Train Accuracy')\n    plt.plot(val_accuracies, label='Validation Accuracy')\n    plt.title('Train vs Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    # Train vs Validation Loss\n    plt.subplot(1, 2, 2)\n    plt.plot(train_losses, label='Train Loss')\n    plt.plot(val_losses, label='Validation Loss')\n    plt.title('Train vs Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.tight_layout()\n    # Check if save_path directory exists, if not, create it\n    if not os.path.exists(save_path):\n        os.makedirs(save_path)\n\n    # Save the figure\n    plt.savefig(os.path.join(save_path, f'training_validation_plot_epoch_{OPTIMIZER}_{epoch + 1}.png'))\n    plt.show()\n    plt.close()  # Close the figure to free up memory\n\ndef save_and_log(model, epoch, train_loss, val_loss, val_accuracy, train_accuracy, logs_dir):\n    os.makedirs(logs_dir, exist_ok=True)\n    last_model_path = os.path.join(logs_dir, 'last.pth')\n    torch.save(model.state_dict(), last_model_path)\n    print(f'Last model saved to {last_model_path}')\n\n    # Save the best model if the current validation accuracy is better than the best seen so far\n    if epoch > 10:\n        torch.save(model.state_dict(), f'{logs_dir}/check_point_{epoch+1}.pth')\n\n    new_row = {\n        'Epoch': epoch + 1,\n        'Train Loss': train_loss,\n        'Validation Loss': val_loss,\n        'Train Accuracy': train_accuracy,\n        'Validation Accuracy': val_accuracy\n    }\n    # Print each item in the dictionary on a new line with a tab indent\n    for key, value in new_row.items():\n        print(f\"{key}\\t\\t:\\t\\t{value}\")\n\n    csv_path = f'{DATA_PATH}/logs/training_data.csv'\n\n    # Check if the file exists\n    if os.path.exists(csv_path):\n        df = pd.read_csv(csv_path)\n        new_df = pd.DataFrame([new_row])\n        df = pd.concat([df, new_df], ignore_index=True)\n    else:\n        df = pd.DataFrame([new_row])\n\n    df.to_csv(csv_path, index=False)\n    print(new_row)\n    print(f'Training data updated in {csv_path}')\n    \n    \ndef train(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n    train_accuracies = []\n    val_accuracies = []\n    train_losses = []\n    val_losses = []\n\n    for epoch in range(num_epochs):\n        train_loss, train_accuracy = train_epoch(model, train_loader, criterion, optimizer, device)\n        val_loss, val_accuracy = validate(model, val_loader, criterion, device)\n\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        train_accuracies.append(train_accuracy)\n        val_accuracies.append(val_accuracy)\n        \n        best_val_accuracy = max(val_accuracies)\n\n        \n        save_and_log(tb_model, epoch, train_losses[-1], val_losses[-1], val_accuracies[-1], train_accuracies[-1],  f'{DATA_PATH}/logs')\n        print(\"\\n\\n\\nVisualization\\n\\n\\n\")\n        visualize_training_data(train_accuracies, val_accuracies, train_losses, val_losses, epoch)\n        print(f\"\\n\\n\\nEpoch [{epoch + 1} / {NUM_OF_EPOCHS}] completed ✅ \\n\\n\\n\")\n\n    print('\\n\\n✅ Training completed.\\n\\n')\n\n","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-02-24T03:16:18.243312Z","start_time":"2024-02-24T03:16:18.232684Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-04T15:05:03.090183Z","iopub.execute_input":"2024-03-04T15:05:03.090785Z","iopub.status.idle":"2024-03-04T15:05:03.116940Z","shell.execute_reply.started":"2024-03-04T15:05:03.090754Z","shell.execute_reply":"2024-03-04T15:05:03.115917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntb_model = TuberculosisCNNReduced().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(tb_model.parameters(), lr=LEARNING_RATE)\n\n\n# Optimizer setup based on the OPTIMIZER constant\nif OPTIMIZER == 'Adam':\n    optimizer = optim.Adam(tb_model.parameters(), lr=LEARNING_RATE)\nelif OPTIMIZER == 'SGD':\n    optimizer = optim.SGD(tb_model.parameters(), lr=LEARNING_RATE, momentum=0.9)\nelif OPTIMIZER == 'RMSprop':\n    optimizer = optim.RMSprop(tb_model.parameters(), lr=LEARNING_RATE)\nelif OPTIMIZER == 'AdamW':\n    optimizer = optim.AdamW(tb_model.parameters(), lr=LEARNING_RATE)\n# Add more optimizers as needed\nelse:\n    raise ValueError(\"Unsupported optimizer\")","metadata":{"execution":{"iopub.status.busy":"2024-03-04T15:05:04.038014Z","iopub.execute_input":"2024-03-04T15:05:04.038735Z","iopub.status.idle":"2024-03-04T15:05:04.613164Z","shell.execute_reply.started":"2024-03-04T15:05:04.038705Z","shell.execute_reply":"2024-03-04T15:05:04.612347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove all logs that consume most of the storage before training a new set\n# !rm -r data/logs\n# !rm -r /kaggle/working/data/output_2024_02_24_06_13_42.zip\n# !rm -r /kaggle/working/training_plots","metadata":{"execution":{"iopub.status.busy":"2024-03-04T15:05:05.216081Z","iopub.execute_input":"2024-03-04T15:05:05.216946Z","iopub.status.idle":"2024-03-04T15:05:05.220881Z","shell.execute_reply.started":"2024-03-04T15:05:05.216911Z","shell.execute_reply":"2024-03-04T15:05:05.219954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(tb_model, train_loader, val_loader, criterion, optimizer, NUM_OF_EPOCHS, device)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T15:05:05.538863Z","iopub.execute_input":"2024-03-04T15:05:05.539685Z","iopub.status.idle":"2024-03-04T16:02:13.413956Z","shell.execute_reply.started":"2024-03-04T15:05:05.539651Z","shell.execute_reply":"2024-03-04T16:02:13.413035Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !rm -r /kaggle/working/training_plots_2024_03_04.zip\n# !rm -r /kaggle/working/logs_2024_03_04.zip\n# !rm -r /kaggle/working/training_plots_2024_03_04_14_29_34.zip","metadata":{"execution":{"iopub.status.busy":"2024-03-04T14:30:17.782804Z","iopub.execute_input":"2024-03-04T14:30:17.783475Z","iopub.status.idle":"2024-03-04T14:30:17.787689Z","shell.execute_reply.started":"2024-03-04T14:30:17.783438Z","shell.execute_reply":"2024-03-04T14:30:17.786790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nimport datetime\n\ndef zip_directories():\n    # Get the current date in snake_case format\n    date_str = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n    # Define the directories to zip\n    training_plots_dir = '/kaggle/working/training_plots'\n    logs_dir = '/kaggle/working/data/logs'\n\n    # Define the base directory for the zip files\n    base_dir = '/kaggle/working'\n\n    # Zip the training_plots directory\n    shutil.make_archive(f'{base_dir}/training_plots_{date_str}', 'zip', training_plots_dir)\n\n    # Zip the logs directory with the current date in the filename\n#     shutil.make_archive(f'{base_dir}/logs_{date_str}', 'zip', logs_dir)\n\n    print(f\"Created zip: {base_dir}/training_plots_{date_str}.zip\")\n#     print(f\"Created zip: {base_dir}/logs_{date_str}.zip\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:16:05.065410Z","iopub.execute_input":"2024-03-04T16:16:05.066181Z","iopub.status.idle":"2024-03-04T16:16:05.072135Z","shell.execute_reply.started":"2024-03-04T16:16:05.066149Z","shell.execute_reply":"2024-03-04T16:16:05.071074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Call the function to create the zip files\nzip_directories()","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:16:06.232598Z","iopub.execute_input":"2024-03-04T16:16:06.232960Z","iopub.status.idle":"2024-03-04T16:16:06.625518Z","shell.execute_reply.started":"2024-03-04T16:16:06.232926Z","shell.execute_reply":"2024-03-04T16:16:06.624581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport os\nfrom tqdm import tqdm\n\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_curve, auc\nfrom itertools import cycle\n\n\ndef plot_roc_curve(fpr, tpr, roc_auc, num_classes):\n    plt.figure(figsize=(7, 7))\n    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n    for i, color in zip(range(num_classes), colors):\n        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n                 label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n\n    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) - multi-class')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    \ndef plot_confusion_matrix(true_labels, predicted_labels):\n    cm = confusion_matrix(true_labels, predicted_labels)\n    plt.figure(figsize=(8, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', square=True, xticklabels=True, yticklabels=True)\n    plt.xlabel('Predicted Labels')\n    plt.ylabel('True Labels')\n    plt.title('Confusion Matrix')\n    \n    save_path = 'training_plots'\n    # Check if save_path directory exists, if not, create it\n    if not os.path.exists(save_path):\n        os.makedirs(save_path)\n\n    # Save the figure\n    plt.savefig(os.path.join(save_path, 'confusion_matrix.png'))\n    plt.show()\n    plt.close()\n\ndef prf1_table(true_labels, predicted_labels):\n    precision, recall, f1_score, _ = precision_recall_fscore_support(true_labels, predicted_labels)\n    metrics_df = pd.DataFrame({\n        'Class': range(len(precision)),\n        'Precision': precision,\n        'Recall': recall,\n        'F1 Score': f1_score\n    })\n    print(metrics_df)\n\n    \ndef test(model, test_loader, criterion, device, checkpoint_path):\n    # Load the trained model from the checkpoint\n    model.load_state_dict(torch.load(checkpoint_path))\n    model.to(device)\n    model.eval()\n\n    test_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_true = []\n    all_scores = []  # List to store all the model's output scores for the positive class\n\n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Testing\"):\n            images = batch['image'].to(device)\n            labels = batch['label'].to(device)\n            outputs = model(images)\n\n            loss = criterion(outputs, labels)\n            test_loss += loss.item() * images.size(0)\n\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n            all_preds.extend(predicted.cpu().numpy())\n            all_true.extend(labels.cpu().numpy())\n            # For binary classification, store the score of the positive class\n            all_scores.extend(outputs.cpu().numpy()[:, 1])  # Assuming index 1 is the positive class\n\n    test_accuracy = correct / total\n    print(f'Test Loss: {test_loss / len(test_loader.dataset):.4f}, Test Accuracy: {test_accuracy:.4f}')\n\n    # Convert true labels and scores to numpy arrays\n    all_true_array = np.array(all_true)\n    all_scores_array = np.array(all_scores)\n\n    # Compute ROC curve and ROC area\n    fpr, tpr, _ = roc_curve(all_true_array, all_scores_array)\n    roc_auc = auc(fpr, tpr)\n\n    cm = confusion_matrix(all_true, all_preds)  # Compute confusion matrix for further analysis\n    # Plot ROC curve\n    plt.figure()\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC)')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return all_true, all_preds, cm\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T17:26:38.230510Z","iopub.execute_input":"2024-03-04T17:26:38.230913Z","iopub.status.idle":"2024-03-04T17:26:38.252922Z","shell.execute_reply.started":"2024-03-04T17:26:38.230884Z","shell.execute_reply":"2024-03-04T17:26:38.251896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport shutil\n\ndef zip_best_model_and_plot(csv_path, models_dir, plots_dir, output_zip_path):\n    # Load the training data\n    print(\"Zipping best epochs logs (.pth and corresponding log images) ....\")\n    df = pd.read_csv(csv_path)\n    \n    # Select the best epoch: here we use the highest validation accuracy\n    # You can change it to use the lowest validation loss if you prefer\n    best_epoch_row = df.loc[df['Validation Accuracy'].idxmax()]\n    best_epoch = int(best_epoch_row['Epoch'])\n    \n    # Construct the filenames for the best model and corresponding plot\n    # Adjust the filename patterns based on your actual naming conventions\n    best_model_filename = f'check_point_{best_epoch}.pth'\n    best_plot_filename = f'training_validation_plot_epoch_{OPTIMIZER}_{best_epoch}.png'\n    \n    # Define the paths for the best model and plot\n    best_model_path = os.path.join(models_dir, best_model_filename)\n    best_plot_path = os.path.join(plots_dir, best_plot_filename)\n    \n    # Check if the files exist\n    if not os.path.exists(best_model_path) or not os.path.exists(best_plot_path):\n        raise FileNotFoundError(\"The best model or plot file does not exist.\")\n    \n    # Create a temporary directory to hold the files for zipping\n    temp_dir = os.path.join('/tmp', 'best_model_and_plot')\n    os.makedirs(temp_dir, exist_ok=True)\n    \n    # Copy the best model and plot to the temporary directory\n    shutil.copy(best_model_path, temp_dir)\n    shutil.copy(best_plot_path, temp_dir)\n    \n    # Create a zip file containing the best model and plot\n    shutil.make_archive(output_zip_path, 'zip', temp_dir)\n    \n    # Clean up the temporary directory\n    shutil.rmtree(temp_dir)\n    \n    print(f\"Created zip file with the best model and plot: {output_zip_path}.zip\")\n    return best_epoch\n\n# Example usage\ncsv_path = '/kaggle/working/data/logs/training_data.csv'\nmodels_dir = '/kaggle/working/data/logs'\nplots_dir = '/kaggle/working/training_plots'\noutput_zip_path = '/kaggle/working/best_model_and_plot'\n\n# best_epoch = zip_best_model_and_plot(csv_path, models_dir, plots_dir, output_zip_path)\n\nprint(f\" 🟢 Best epoch : {best_epoch}\\n ✅ Logs saved on : {output_zip_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T17:26:38.713584Z","iopub.execute_input":"2024-03-04T17:26:38.714440Z","iopub.status.idle":"2024-03-04T17:26:38.725189Z","shell.execute_reply.started":"2024-03-04T17:26:38.714405Z","shell.execute_reply":"2024-03-04T17:26:38.724193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the path to your saved model checkpoint\ncheckpoint_path = f'{DATA_PATH}/logs/check_point_20.pth'\n\n# Call the test function\ntrue_labels, predicted_labels,cm = test(tb_model, test_loader, criterion, device, checkpoint_path)\n\n# Plot the confusion matrix\nplot_confusion_matrix(true_labels, predicted_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T17:26:40.746929Z","iopub.execute_input":"2024-03-04T17:26:40.747376Z","iopub.status.idle":"2024-03-04T17:26:56.169041Z","shell.execute_reply.started":"2024-03-04T17:26:40.747344Z","shell.execute_reply":"2024-03-04T17:26:56.168092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\nimport numpy as np\n\ndef plot_roc_curve(true_labels, scores, num_classes):\n    # Compute ROC curve and ROC area for each class\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n\n    # Convert labels to one-hot encoding\n    true_labels_one_hot = np.eye(num_classes)[true_labels]\n\n    for i in range(num_classes):\n        fpr[i], tpr[i], _ = roc_curve(true_labels_one_hot[:, i], scores[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Plot all ROC curves\n    plt.figure()\n    colors = cycle(['blue', 'red', 'green', 'cyan', 'magenta', 'yellow', 'black', 'pink', 'lightblue', 'lightgreen', 'gray', 'indigo', 'orange', 'brown', 'purple'])\n    for i, color in zip(range(num_classes), colors):\n        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n                 label='ROC curve of class {0} (area = {1:0.2f})'\n                 ''.format(i, roc_auc[i]))\n\n    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) for multi-class')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T17:18:04.603244Z","iopub.execute_input":"2024-03-04T17:18:04.603851Z","iopub.status.idle":"2024-03-04T17:18:04.614365Z","shell.execute_reply.started":"2024-03-04T17:18:04.603818Z","shell.execute_reply":"2024-03-04T17:18:04.613379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prf1_table(true_labels, predicted_labels)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T18:16:03.137299Z","iopub.execute_input":"2024-03-04T18:16:03.138215Z","iopub.status.idle":"2024-03-04T18:16:03.162912Z","shell.execute_reply.started":"2024-03-04T18:16:03.138178Z","shell.execute_reply":"2024-03-04T18:16:03.162048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## End of training","metadata":{}},{"cell_type":"markdown","source":"# External Testing","metadata":{}},{"cell_type":"code","source":"class ExternalTestDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        img_name = row['FILE NAME']\n        class_name = row['CLASS_NAME']\n        format = row['FORMAT'].lower()\n        img_path = row['IMAGE PATH']\n        image = Image.open(img_path)\n        label = row['CLASS_ID']\n\n        if self.transform:\n            image = self.transform(image)\n\n        sample = {'image': image, 'label': label, 'img_path': img_path, 'attributes': row.to_dict()}\n        return sample\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T19:07:28.672001Z","iopub.execute_input":"2024-03-04T19:07:28.672444Z","iopub.status.idle":"2024-03-04T19:07:28.681375Z","shell.execute_reply.started":"2024-03-04T19:07:28.672411Z","shell.execute_reply":"2024-03-04T19:07:28.680254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndef convert_external_dataset(external_csv_path, output_data_path, image_format='PNG'):\n    \n    def get_clean_filename(x):\n        file_name = x.split('\\\\n')[0]\n        return f\"{DATA_PATH}/external_test/{file_name}\"\n        \n    \n    # Read the external dataset CSV into a DataFrame\n    external_df = pd.read_csv(external_csv_path)\n\n    # Convert the external DataFrame into the format of your own dataset DataFrame\n    converted_df = external_df[['study_id', 'findings']].copy()\n    converted_df.rename(columns={'study_id': 'FILE NAME', 'findings': 'CLASS_NAME'}, inplace=True)\n\n    # Add the 'SIZE', 'CLASS_ID', and 'FORMAT' columns, filling them with default or derived values\n    converted_df['SIZE'] = 'Unknown'  # Assuming the actual size is unknown; adjust if you have this information\n    converted_df['CLASS_ID'] = converted_df['CLASS_NAME'].apply(lambda x: 0 if x.lower() == 'normal' else 1)\n    converted_df['IMAGE PATH'] = converted_df['FILE NAME'].apply(lambda x: get_clean_filename(x))\n#     converted_df['CLASS_NAME'] = converted_df['CLASS_ID'].apply(lambda x: 'Tuberculosis' if x == 1 else 'Normal')\n    \n    converted_df['FORMAT'] = image_format\n\n    # Reorder the columns to match your own dataset DataFrame\n    converted_df = converted_df[['FILE NAME', 'SIZE', 'CLASS_ID', 'CLASS_NAME', 'FORMAT', 'IMAGE PATH']]\n\n    # Save the converted DataFrame to a new CSV file\n    output_csv_path = f'{output_data_path}/converted_shenzhen_metadata.csv'\n    converted_df.to_csv(output_csv_path, index=False)\n\n    print(f'Converted DataFrame saved to {output_csv_path}')","metadata":{"execution":{"iopub.status.busy":"2024-03-04T19:26:30.274235Z","iopub.execute_input":"2024-03-04T19:26:30.275159Z","iopub.status.idle":"2024-03-04T19:26:30.287785Z","shell.execute_reply.started":"2024-03-04T19:26:30.275118Z","shell.execute_reply":"2024-03-04T19:26:30.286806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the paths\nexternal_csv_path = '/kaggle/input/tuberculosis-chest-xrays-shenzhen/shenzhen_metadata.csv'\noutput_data_path = DATA_PATH  # Replace 'your_data_path_here' with the actual path\n\n# Call the function\nconvert_external_dataset(external_csv_path, output_data_path)\n\nexternal_df = pd.read_csv('/kaggle/working/data/converted_shenzhen_metadata.csv')\nexternal_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-04T19:26:30.543856Z","iopub.execute_input":"2024-03-04T19:26:30.544239Z","iopub.status.idle":"2024-03-04T19:26:30.575897Z","shell.execute_reply.started":"2024-03-04T19:26:30.544207Z","shell.execute_reply":"2024-03-04T19:26:30.574867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_random_external_samples(df, class_column, n_samples_per_class):\n    # Separate the DataFrame into two DataFrames based on the class\n    df_class_0 = df[df[class_column] == 0]\n    df_class_1 = df[df[class_column] == 1]\n    \n    # Sample n_samples_per_class from each DataFrame\n    # If a class has fewer instances than n_samples_per_class, all instances are returned\n    # The replace=True parameter allows for sampling with replacement if needed\n    df_class_0_sampled = df_class_0.sample(min(len(df_class_0), n_samples_per_class), replace=True, random_state=42)\n    df_class_1_sampled = df_class_1.sample(min(len(df_class_1), n_samples_per_class), replace=True, random_state=42)\n    \n    # Concatenate the sampled DataFrames to create a balanced DataFrame\n    balanced_df = pd.concat([df_class_0_sampled, df_class_1_sampled], ignore_index=True)\n    \n    # Shuffle the DataFrame before returning\n    shuffled_balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n    \n    return shuffled_balanced_df\n\n# Specify the number of samples you want for each class\nn_samples = 70  # Adjust this number as needed\n\n# Create a new balanced and shuffled DataFrame\nbalanced_shuffled_external_df = get_random_external_samples(external_df, 'CLASS_ID', n_samples)\n\nfinal_test_df = pd.concat([test_df.head(len(test_df) - int(n_samples) * 2), balanced_shuffled_external_df])\nfinal_test_df.tail()","metadata":{"execution":{"iopub.status.busy":"2024-03-04T19:31:45.405818Z","iopub.execute_input":"2024-03-04T19:31:45.406286Z","iopub.status.idle":"2024-03-04T19:31:45.429317Z","shell.execute_reply.started":"2024-03-04T19:31:45.406252Z","shell.execute_reply":"2024-03-04T19:31:45.428229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"external_test_dataset = ExternalTestDataset(final_test_df, transform=T)\nexternal_test_loader = DataLoader(external_test_dataset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T19:31:45.988938Z","iopub.execute_input":"2024-03-04T19:31:45.989790Z","iopub.status.idle":"2024-03-04T19:31:45.994143Z","shell.execute_reply.started":"2024-03-04T19:31:45.989756Z","shell.execute_reply":"2024-03-04T19:31:45.993223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(final_test_df)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T19:31:46.352383Z","iopub.execute_input":"2024-03-04T19:31:46.353010Z","iopub.status.idle":"2024-03-04T19:31:46.358654Z","shell.execute_reply.started":"2024-03-04T19:31:46.352977Z","shell.execute_reply":"2024-03-04T19:31:46.357721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the path to your saved model checkpoint\ncheckpoint_path = f'{DATA_PATH}/logs/check_point_20.pth'\n\n# Call the test function\ntrue_labels, predicted_labels,cm = test(tb_model, external_test_loader, criterion, device, checkpoint_path)\n\n# Plot the confusion matrix\nplot_confusion_matrix(true_labels, predicted_labels)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T19:31:47.736311Z","iopub.execute_input":"2024-03-04T19:31:47.737205Z","iopub.status.idle":"2024-03-04T19:32:21.691215Z","shell.execute_reply.started":"2024-03-04T19:31:47.737171Z","shell.execute_reply":"2024-03-04T19:32:21.690263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prf1_table(true_labels, predicted_labels)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T19:33:08.304500Z","iopub.execute_input":"2024-03-04T19:33:08.304877Z","iopub.status.idle":"2024-03-04T19:33:08.328767Z","shell.execute_reply.started":"2024-03-04T19:33:08.304845Z","shell.execute_reply":"2024-03-04T19:33:08.327769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}